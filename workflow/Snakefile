from Bio import SeqIO

configfile: "config.yaml"

# Set up the file with all the accession numbers of proteins to download from AlphaFold
with open("workflow/alphafold.txt") as ids:
    alphafold_list = [line.strip() for line in ids]

# Set up the file with all the accession numbers of reference Rhodopsins to download from RCSB
with open("workflow/pdb.txt") as ids:
    pdb_list = [line.split()[0] for line in ids]

# Set up the file with all accession numbers of cluster representatives
with open("workflow/clstr_list.txt") as reps:
    clstr_list = [line.split()[0] for line in reps]

# Set up the file with all the queries to test the alignment om
with open("analysis/queries/tst_list.txt") as queries:
    query_list = [line.split()[0] for line in queries]

# Set up lists according to the config file
c_list = config["c"]
i_list = config["i"]
n_reps = config["n"]
methods = config["prws_aln_meth"]
ref_pdb = config["ref_pdb"]

wildcard_constraints:
    pdb = "|".join(alphafold_list + pdb_list),
    rep = "|".join(clstr_list),
    query = "|".join(query_list)

# Define the final targets of the workflow
rule all:
    input:
        expand("analysis/data/alphafold/{pdb}/struct.pdb", pdb = alphafold_list),
        expand("analysis/data/pdb/{pdb}/struct_raw.pdb", pdb = pdb_list),
        expand("analysis/clustering/mmseqs_{i}_cluster.tsv", i = i_list),
        expand("analysis/clustering/cd_hit_{c}_rep_seq.fasta.clstr", c = c_list),
        expand("analysis/results/{query}/alignments/{rep}_{query}_aa.fa", query = query_list, rep = clstr_list),
        expand("analysis/results/{query}/membrane_pos_{query}_{n_reps}.json", query = query_list, n_reps = n_reps)


# Download AlphaFold pdb files according to the full list provided
rule dload_alphafold:
    output:
       "analysis/data/alphafold/{pdb}/struct.pdb"
    resources:
        af_dload = 1
    shell:
        "wget -qO {output} https://alphafold.ebi.ac.uk/files/AF-{wildcards.pdb}-F1-model_v4.pdb"

# Download RCSB pdb files according to the Rhodopsin reference list provided
rule dload_pdb:
    output:
        "analysis/data/pdb/{pdb}/struct_raw.pdb"
    resources:
        pdb_dload = 1
    shell:
        "wget -qO {output} https://files.rcsb.org/download/{wildcards.pdb}.pdb"

# Fix the RCSB pdb files - remove the ligand atoms
rule fix_pdb:
    input:
        model = "analysis/data/pdb/{pdb}/struct_raw.pdb",
        atom_map = "workflow/atom_map.json"
    output:
        "analysis/data/pdb/{pdb}/struct_fixed.pdb"
    conda:
        "envs/pymol.yaml"
    script:
        "scripts/fix_structures.py"

# Trim helix
rule trim_helix:
    input:
        "analysis/data/{database}/{pdb}/struct_fixed.pdb"
    output:
        "analysis/data/{database}/{pdb}/struct.pdb"
    conda:
        "envs/biopython.yaml"
    script:
        "scripts/trim_helix.py"

# Align each protein to the reference Rhodopsin (BR) using FoldMason
rule foldmason_aln:
    input:
        ref = f"analysis/data/pdb/{ref_pdb}/struct.pdb",
        query = "analysis/data/{database}/{pdb}/struct.pdb"
    output:
        "analysis/data/{database}/{pdb}/aln_to_br_aa.fa"
    params:
        prefix = lambda w, output: str(output).replace('_aa.fa', '')
    conda:
        "envs/foldmason.yaml"
    shell:
        "foldmason easy-msa {input.query} {input.ref} {params.prefix} {resources.tmpdir} --report-mode 2"

# Convert pdb files to fasta
rule pdb_to_fasta:
    input:
        "analysis/data/{database}/{pdb}/struct.pdb"
    output:
        "analysis/data/{database}/{pdb}/raw_sequence.fasta"
    shell:
        "pdb_tofasta {input} > {output} && sed -i '1s/.*/>{wildcards.pdb}/' {output}"

# Fix fasta files by removing X amino acids (ligands or unclear) ONLY from the c and n termini
rule fix_fasta:
    input:
        "analysis/data/{database}/{pdb}/raw_sequence.fasta"
    output:
        "analysis/data/{database}/{pdb}/short.fasta"
    shell:
        "seqkit replace -sp '^X+|X+$' {input} -o {output}"

# Align each protein to the reference Rhodopsin (BR) using t-coffee
rule t_coffee_aln:
    input:
        ref = f"analysis/data/pdb/{ref_pdb}/short.fasta",
        query = "analysis/data/{database}/{pdb}/short.fasta"
    output:
        "analysis/data/{database}/{pdb}/aln_to_br_t_coffee.fa"
    conda:
        "envs/t_coffee.yaml"
    shell:
        "t_coffee -in {input.ref} {input.query} -output fasta_aln -outfile {output}"

rule t_coffee_pairwise_template:
    input:
        ref_p = f"analysis/data/pdb/{ref_pdb}/struct.pdb",
        query_p = "analysis/data/{database}/{pdb}/struct.pdb"
    output:
        "analysis/data/{database}/{pdb}/t_coffee_input.txt"
    run:
        with open(str(output), 'w') as out:
            out.write(f">{ref_pdb}  _P_ {input.ref_p}\n")
            out.write(f">{wildcards.pdb}  _P_ {input.query_p}\n")

# Align each protein to the reference Rhodopsin (BR) using t-coffee 3d alignment
rule t_coffee_3d_aln:
    input:
        ref_p = f"analysis/data/pdb/{ref_pdb}/struct.pdb",
        query_p = "analysis/data/{database}/{pdb}/struct.pdb",
        ref_s = f"analysis/data/pdb/{ref_pdb}/short.fasta",
        query_s = "analysis/data/{database}/{pdb}/short.fasta",
        template = "analysis/data/{database}/{pdb}/t_coffee_input.txt"
    output:
        "analysis/data/{database}/{pdb}/aln_to_br_coffee_3d.fa"
    params:
        methods = "sap_pair,mustang_pair,t_coffee_msa,probcons_msa"
    conda:
        "envs/t_coffee.yaml"
    shell:
        "t_coffee {input.ref_s} {input.query_s} -output fasta_aln -outfile {output} -method {params.methods} -template_file {input.template} -pdb_min_sim 0 -pdb_min_cov 0 -n_core 1"

# Align each protein to the reference Rhodopsin (BR) using tm-align
rule tm_aln:
    input:
        ref_p = f"analysis/data/pdb/{ref_pdb}/struct.pdb",
        query_p = "analysis/data/{database}/{pdb}/struct.pdb"
    output:
        "analysis/data/{database}/{pdb}/aln_to_br_tm.aln"
    conda:
        "envs/tm_aln.yaml"
    shell:
        "TMalign {input.ref_p} {input.query_p} > {output}"

# For the list of reference rhodopsins run tm-algin with benchmark directive to check resource management
rule resource_check_tm_align:
    input:
        ref_p = f"analysis/data/pdb/{ref_pdb}/struct.pdb",
        query_p = "analysis/data/pdb/{pdb}/struct.pdb"
    output:
        "analysis/data/pdb/{pdb}/bnch_aln_to_br_tm.aln"
    conda:
        "envs/tm_aln.yaml"
    benchmark:
        repeat("analysis/data/pdb/{pdb}/tm_benchmakr.tsv", 100)
    shell:
        "TMalign {input.ref_p} {input.query_p} > {output}"

# For the list of reference rhodopsins run foldmason with benchmark directive to check resource management.
rule resource_check_foldmason:
    input:
        ref = f"analysis/data/pdb/{ref_pdb}/struct.pdb",
        query = "analysis/data/pdb/{pdb}/struct.pdb"
    output:
        "analysis/data/pdb/{pdb}/bnch_aln_to_br_aa.fa"
    params:
        prefix = lambda w, output: str(output).replace('_aa.fa', '')
    conda:
        "envs/foldmason.yaml"
    benchmark:
        repeat("analysis/data/pdb/{pdb}/fm_benchmark.tsv", 100)
    shell:
        "foldmason easy-msa {input.query} {input.ref} {params.prefix} {resources.tmpdir} --report-mode 2"

# Trim each fasta file according to the BR alignment and filter according to RMSD & alignment length.
rule prot_trim_filter:
    input:
        aln = "analysis/data/{database}/{pdb}/aln_to_br_tm.aln",
        pdb = "analysis/data/{database}/{pdb}/struct.pdb"
    output:
        fasta = "analysis/data/{database}/{pdb}/{pdb}.fasta",
        pdb = "analysis/data/{database}/{pdb}/{pdb}.pdb"
    params:
        ref=ref_pdb,
        br_prefix_n=config["br_prefix_n"],
        br_suffix_c=config["br_suffix_c"],
        max_missing_n=config["max_missing_n"],
        max_missing_c=config["max_missing_c"],
        ref_lys_pos=config["ref_lysine_pos"],
        max_rmsd=config["max_rmsd"],
        min_aln_len=config["min_align_len"],
        min_len=config["min_len"],
        max_len=config["max_len"]
    conda:
        "envs/biopython.yaml"
    script:
        "scripts/prot_trim_filter.py"

# Add all the protein fasta files into a single file for clustering, reference proteins as is while the rest as trimmed versions.
rule all_fasta:
    input:
        expand("analysis/data/alphafold/{pdb}/{pdb}.fasta", pdb = alphafold_list),
        expand("analysis/data/pdb/{pdb}/{pdb}.fasta", pdb = pdb_list)
    output:
        "analysis/clustering/all_sequences.fasta"
    shell:
        "seqkit seq {input} -m 1 > {output}"

# Cluster all the sequences using cd-hit with diffrerent -c values for analysis
rule cluster_cd_hit:
    input:
        "analysis/clustering/all_sequences.fasta"
    output:
        rep = "analysis/clustering/cd_hit_{c}_rep_seq.fasta",
        clstr = "analysis/clustering/cd_hit_{c}_rep_seq.fasta.clstr"
    shell:
        "cd-hit -i {input} -o {output.rep} -c 0.{wildcards.c} -n 2"

# As the clusters created by cd-hit were shown to be too large for fast MSA, this rule will cluster with mmseqs to get larger clusters
rule cluster_mmseqs:
    input: 
        "analysis/clustering/all_sequences.fasta"
    output:
        tsv = "analysis/clustering/mmseqs_{i}_cluster.tsv",
        rep = "analysis/clustering/mmseqs_{i}_rep_seq.fasta",
        all = "analysis/clustering/mmseqs_{i}_all_seqs.fasta"
    params:
        prefix = lambda w, output: output[0].replace("_cluster.tsv", "")
    conda:
        "envs/mmseqs2.yaml"
    threads:
        10
    shell:
        "mmseqs easy-cluster {input} {params.prefix} tmp --threads {threads} --min-seq-id 0.{wildcards.i} --cov-mode 0"

# Create lists of sequences to remove and to add so that all the reference Rhodopsins from the list above will be representatives of their cluster - cd-hit
rule ready_rep_w_ref_cd_hit:
    input:
        "analysis/clustering/cd_hit_{c}_rep_seq.fasta"
    output:
        "analysis/clustering/temp/cd_hit_{c}_rep_del.txt",
        "analysis/clustering/temp/cd_hit_{c}_ref_add.txt"
    script:
        "scripts/force_ref_seq_cd_hit.py"

# Create lists of sequences to remove and to add so that all the reference Rhodopsins from the list above will be representatives of their cluster - mmseqs
rule ready_rep_w_ref_mmseqs:
    input:
        "analysis/clustering/mmseqs_{i}_rep_seq.fasta",
        "analysis/clustering/mmseqs_{i}_cluster.tsv"
    output:
        "analysis/clustering/temp/mmseqs_{i}_rep_del.txt",
        "analysis/clustering/temp/mmseqs_{i}_ref_add.txt"
    script:
        "scripts/force_ref_seq_mmseqs.py"

# Replace the representatives with the refrerence Rhodopsins according to previous rule - cd-hit
rule final_fasta_cd_hit:
    input:
        original_fasta="analysis/clustering/cd_hit_{c}_rep_seq.fasta",
        all_fasta="analysis/clustering/all_sequences.fasta",
        to_remove="analysis/clustering/temp/cd_hit_{c}_rep_del.txt",
        to_add="analysis/clustering/temp/cd_hit_{c}_ref_add.txt"
    output:
        "analysis/clustering/cd_hit_{c}_rep_seq_final.fasta"
    shell:
        """
        cat <(seqkit grep -vf {input.to_remove} {input.original_fasta}) <(seqkit grep -f {input.to_add} {input.all_fasta}) > {output}
        """

# Replace the representatives with the refrerence Rhodopsins according to previous rule - mmseqs
rule final_fasta_mmseqs:
    input:
        original_fasta="analysis/clustering/mmseqs_{i}_rep_seq.fasta",
        all_fasta="analysis/clustering/all_sequences.fasta",
        to_remove="analysis/clustering/temp/mmseqs_{i}_rep_del.txt",
        to_add="analysis/clustering/temp/mmseqs_{i}_ref_add.txt"
    output:
        "analysis/clustering/mmseqs_{i}_rep_seq_final.fasta"
    shell:
        """
        cat <(seqkit grep -vf {input.to_remove} {input.original_fasta}) <(seqkit grep -f {input.to_add} {input.all_fasta}) > {output}
        """

# Rule to create the pdb files relevant for the fasta file
rule get_pdb_list:
    input: 
        fasta_file = "analysis/clustering/mmseqs_4_rep_seq_final.fasta"
    output:
        "analysis/clustering/mmseqs_4_pdb_list.txt"
    run:
        import os
        pdb_files = []
        for record in SeqIO.parse(input.fasta_file, 'fasta'):
            database = "pdb" if record.id in pdb_list else "alphafold"
            pdb_path = expand("analysis/data/{database}/{pdb}/{pdb}.pdb", database = database, pdb = record.id)[0]
            if os.path.exists(pdb_path):
                with open(pdb_path, "r") as pdb_file:
                    if any(line.startswith('ATOM') for line in pdb_file):
                        pdb_files.append(pdb_path)
        with open(output[0], 'w') as out_file:
            out_file.write(" ".join(pdb_files))

# Create the template file for the 3d-coffee MSA (contains only structures from PDB)
rule t_coffee_msa_template:
    input:
        fasta_file = "analysis/clustering/mmseqs_4_rep_seq_final.fasta",
        pdb_file = "analysis/clustering/mmseqs_4_pdb_list.txt"
    output:
        "analysis/clustering/templates/mmseqs_4_3d_coffee_template.txt"
    run:
        seq_ids = SeqIO.to_dict(SeqIO.parse(input.fasta_file, 'fasta'))
        with open(input.pdb_file, 'r') as pdb_file:
            pdb_files = pdb_file.read().strip().split()
        with open(str(output[0]), 'w') as out:
            for seq_id, pdb_file in zip(seq_ids,pdb_files):
                out.write(f">{seq_id}  _P_ {pdb_file}\n")

# Create the template file for 3d-coffee but only with structures from PDB
rule t_coffee_msa_template_pdb_only:
    input:
        "analysis/clustering/templates/mmseqs_4_3d_coffee_template.txt"
    output:
        "analysis/clustering/templates/mmseqs_4_3d_coffee_template_pdb_only.txt"
    run:
        with open(str(input)) as inp, open(str(output), 'w') as out:
            for line in inp:
                seq_id = line.split()[0][1:]
                if seq_id in pdb_list:
                    out.write(line)

# Run 3d t-coffee MSA for the 40% identity cluster by mmseqs 
rule t_coffee_3d_msa:
    input:
        fasta_file = "analysis/clustering/mmseqs_4_rep_seq_final.fasta",
        template = "analysis/clustering/templates/mmseqs_4_3d_coffee_template.txt"
    output:
        aln = "analysis/clustering/mmseqs_4_t_coffee.aln",
        dnd = "analysis/clustering/mmseqs_4_t_coffee.dnd"
    log:
        "analysis/clustering/mmseqs_4_t_coffee.log"
    params:
        methods = "sap_pair,mustang_pair,t_coffee_msa,probcons_msa"
    threads:
        40
    conda:
        "envs/t_coffee.yaml"
    shell:
        "t_coffee {input.fasta_file} -outfile {output.aln} -newtree {output.dnd} -method {params.methods} -template_file {input.template} -pdb_min_sim 90 -pdb_min_cov 0 -thread {threads} &> {log}"

# For comparing - MSA alignment using foldmason
rule foldmason_msa:
    input:
        fasta_file = "analysis/clustering/mmseqs_4_rep_seq_final.fasta",
        pdb_file = "analysis/clustering/mmseqs_4_pdb_list.txt"
    output:
        "analysis/clustering/mmseqs_4_foldmason_aa.fa"
    params:
        prefix = lambda w, output: str(output).replace('_aa.fa', '')
    threads:
        40
    conda:
        "envs/foldmason.yaml"
    shell:
        "foldmason easy-msa $(cat {input.pdb_file}) {params.prefix} {resources.tmpdir} --report-mode 2"

# For comparing - MSA alignment using MAFFT
rule mafft_seq_msa:
    input:
        "analysis/clustering/mmseqs_4_rep_seq_final.fasta"
    output:
        "analysis/clustering/mmseqs_4_mafft_aln.fa"
    shell:
        "mafft --auto {input} > {output}"

# Create a fasta file from pdb files for queries
rule query_pdb_to_fasta:
    input:
        "analysis/queries/{query}/{query}.pdb"
    output:
        "analysis/queries/{query}/{query}.fasta"
    shell:
        "pdb_tofasta {input} > {output} && sed -i '1s/.*/>{wildcards.query}/' {output}"

# Align queries using t-coffee profiles - NOT WORKING AS EXPECTED
#rule query_aln_pdb:
#    input:
#        query_seq = "analysis/results/queries/{query}.fasta",
#        query_pdb = "analysis/results/queries/{query}.pdb",
#        ref_aln = "analysis/clustering/mmseqs_4_t_coffee.aln",
#        ref_template = "analysis/clustering/templates/mmseqs_4_3d_coffee_template.txt"
#    output:
#        aln = "analysis/results/{query}_3d_aln.aln",
#        template_file = temp("analysis/results/{query}_template")
#    log:
#        "analysis/results/{query}_3d_aln.log"
#    conda:
#        "envs/t_coffee.yaml"
#    params:
#        methods = "sap_pair,mustang_pair,t_coffee_msa,probcons_msa"
#    threads:
#        workflow.cores
#    shell:
#        """
#        cat {input.ref_template} > {output.template_file}
#        echo ">$(seqkit seq --name {input.query_seq})  _P_ {input.query_pdb}" >> {output.template_file}
#        t_coffee -profile {input.ref_aln},{input.query_seq} -method {params.methods} -profile_template_file {output.template_file} -outfile {output.aln} -thread {threads} &> {log}
#        """

# Run Foldmason align for each of the cluster representatives on the query for trimming the query
# TM-align does a poor job when queries are long so a prelimiary alignment for trimming is required to capture rhodopsin domain
rule query_foldmason_aln:
    input:
        ref_p = lambda wildcards: f"analysis/data/pdb/{wildcards.rep}/{wildcards.rep}.pdb" if wildcards.rep in pdb_list
            else f"analysis/data/alphafold/{wildcards.rep}/{wildcards.rep}.pdb",
        query_p = "analysis/queries/{query}/{query}.pdb"
    output:
        "analysis/results/{query}/alignments/{rep}_{query}_aa.fa"
    params:
        prefix = lambda w, output: str(output).replace('_aa.fa', ''),
        tmpdir = lambda w: f"analysis/results/{w.query}/alignments/tmp/{w.rep}"
    conda:
        "envs/foldmason.yaml"
    shell:
        """
        mkdir -p {params.tmpdir} &&
        foldmason easy-msa {input.query_p} {input.ref_p} {params.prefix} {params.tmpdir} --report-mode 2
        """

# Trim the query according to alignments with BR
rule trim_query:
    input:
        query_p = "analysis/queries/{query}/{query}.pdb",
        query_f = "analysis/queries/{query}/{query}.fasta",
        aln_file = "analysis/results/{query}/alignments/7Z09_{query}_aa.fa"
    output:
        trim_p = "analysis/queries/{query}/trimmed/query.pdb",
        trim_f = "analysis/queries/{query}/trimmed/query.fasta"
    params:
        max_query_len=config["max_query_len"],
        query_padding=config["query_padding"]
    script:
        "scripts/trim_query.py"

# Run TM-aling for each of cluster representative on the query
rule query_tm_aln:
    input:
        ref_p = lambda wildcards: f"analysis/data/pdb/{wildcards.rep}/{wildcards.rep}.pdb" if wildcards.rep in pdb_list 
            else f"analysis/data/alphafold/{wildcards.rep}/{wildcards.rep}.pdb",
        query_p = "analysis/queries/{query}/trimmed/query.pdb"
    output:
        "analysis/results/{query}/alignments/{rep}_{query}.aln"
    conda:
        "envs/tm_aln.yaml"
    shell:
        "TMalign {input.ref_p} {input.query_p} > {output}"

# Create a list of a set amount of representatives to use for final alignment for query
rule chose_reps_aln:
    input:
        ref_aln = expand("analysis/results/{{query}}/alignments/{rep}_{{query}}.aln", rep = clstr_list)
    output:
        rep_lists = expand("analysis/results/{{query}}/list_reps_to_aln_{n_reps}.txt", n_reps=n_reps)
    params:
        must_reps=pdb_list,
        n_reps=n_reps
    script:
        "scripts/score_alignment.py"

# Create fasta file for query alignment
rule query_reps_fasta:
    input:
        rep_list = "analysis/results/{query}/list_reps_to_aln_{n_reps}.txt",
        query_fasta = "analysis/queries/{query}/trimmed/query.fasta"
    output:
        "analysis/results/{query}/to_align_{n_reps}.fasta"
    run:
        with open(input.rep_list, 'r') as f:
            reps = [line.strip() for line in f]
        fasta_files = []
        for rep in reps:
            database = "pdb" if rep in pdb_list else "alphafold"
            fasta_files.append(f"analysis/data/{database}/{rep}/{rep}.fasta")
        with open(output[0], 'w') as out_f:
            with open(input.query_fasta, 'r') as q:
                out_f.write(q.read())
            for fasta in fasta_files:
                with open(fasta, 'r') as f:
                    out_f.write(f.read())

# Create a template for query alignment
rule query_reps_template:
    input:
        "analysis/results/{query}/list_reps_to_aln_{n_reps}.txt"
    output:
        "analysis/results/{query}/3d_coffee_template_{n_reps}.txt"
    run:
        with open(input[0], 'r') as f:
            reps = [line.strip() for line in f]
        with open(output[0], 'w') as out_f:
            out_f.write(f">{wildcards.query}  _P_ analysis/queries/{wildcards.query}/trimmed/query.pdb\n")
            for rep in reps:
                database = 'pdb' if rep in pdb_list else 'alphafold'
                out_f.write(f">{rep}  _P_ analysis/data/{database}/{rep}/{rep}.pdb\n") 

# Align query using  3d t-coffee MSA 
rule query_t_coffee_3d_msa:
    input:
        fasta_file = "analysis/results/{query}/to_align_{n_reps}.fasta",
        template = "analysis/results/{query}/3d_coffee_template_{n_reps}.txt"
    output:
        aln = "analysis/results/{query}/{query}_{n_reps}.aln",
        dnd = "analysis/results/{query}/{query}_{n_reps}.dnd"
    log:
        "analysis/results/{query}/{query}_{n_reps}.log"
    params:
        methods = "sap_pair,mustang_pair,t_coffee_msa,probcons_msa"
    threads:
        40
    conda:
        "envs/t_coffee.yaml"
    shell:
        "t_coffee {input.fasta_file} -outfile {output.aln} -newtree {output.dnd} -method {params.methods} -template_file {input.template} -pdb_min_sim 90 -pdb_min_cov 0 -thread {threads} &> {log}"

# Benchmarking for different number of representatives to align with the query
rule benchmark_query_aln:
    input:
        fasta_file = "analysis/results/{query}/to_align_{n_reps}.fasta",
        template = "analysis/results/{query}/3d_coffee_template_{n_reps}.txt"
    output:
        aln = "analysis/results/benchmark/{query}_{n_reps}.aln",
        dnd = "analysis/results/benchmark/{query}_{n_reps}.dnd"
    log:
        "analysis/results/{query}/{query}_{n_reps}.log"
    params:
        methods = "sap_pair,mustang_pair,t_coffee_msa,probcons_msa"
    threads:
        40
    conda:
        "envs/t_coffee.yaml"
    benchmark:
        repeat("analysis/benchmark/{query}_benchmark_{n_reps}.tsv", 10)
    shell:
        "t_coffee {input.fasta_file} -outfile {output.aln} -newtree {output.dnd} -method {params.methods} -template_file {input.template} -pdb_min_sim 90 -pdb_min_cov 0 -thread {threads} &> {log}"

# Create a json file with mapping for BR positions inside membrane aligned against query positions
rule query_membrane_pos:
    input:
        "analysis/results/{query}/{query}_{n_reps}.aln"
    output:
        "analysis/results/{query}/membrane_pos_{query}_{n_reps}.json"
    script:
        "scripts/tm_pos.py"
